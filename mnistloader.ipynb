{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from functools import partial\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "lt_conv_kwargs = {'kernel_size': 3, 'padding': 'same', 'bias': False}\n",
    "\n",
    "batchsize = 1024\n",
    "bias_scaler = 56\n",
    "\n",
    "hyp = {\n",
    "    'opt': {\n",
    "        'bias_lr':        1.64 * bias_scaler/512, \n",
    "        'non_bias_lr':    1.64 / 512,\n",
    "        'bias_decay':     1.08 * 6.45e-4 * batchsize/bias_scaler,\n",
    "        'non_bias_decay': 1.08 * 6.45e-4 * batchsize,\n",
    "        'scaling_factor': 1./9,\n",
    "        'percent_start': .23,\n",
    "        'loss_scale_scaler': 1./128, \n",
    "    },\n",
    "    'misc': {\n",
    "        'ema': {\n",
    "            'epochs': 10, \n",
    "            'decay_base': .95,\n",
    "            'decay_pow': 3.,\n",
    "            'every_n_steps': 5,\n",
    "        },\n",
    "        'device': 'cpu',\n",
    "        'data_location': 'mnist.pt',\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "if not os.path.exists(hyp['misc']['data_location']):\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "        mnist      = torchvision.datasets.MNIST('mnist/', download=True,  train=True,  transform=transform)\n",
    "        mnist_eval = torchvision.datasets.mnist('mnist/', download=false, train=false, transform=transform)\n",
    "\n",
    "        train_dataset_gpu_loader = torch.utils.data.dataloader(mnist, batch_size=len(mnist), drop_last=True,\n",
    "                                                  shuffle=True, num_workers=2, persistent_workers=False)\n",
    "        eval_dataset_gpu_loader = torch.utils.data.DataLoader(mnist_eval, batch_size=len(mnist_eval), drop_last=true,\n",
    "                                                  shuffle=false, num_workers=1, persistent_workers=false)\n",
    "\n",
    "        train_dataset_gpu = {}\n",
    "        eval_dataset_gpu = {}\n",
    "\n",
    "        train_dataset_gpu['images'], train_dataset_gpu['targets'] = [item.to(device=hyp['misc']['device'], non_blocking=True) for item in next(iter(train_dataset_gpu_loader))]\n",
    "        eval_dataset_gpu['images'],  eval_dataset_gpu['targets']  = [item.to(device=hyp['misc']['device'], non_blocking=True) for item in next(iter(eval_dataset_gpu_loader)) ]\n",
    "\n",
    "\n",
    "        data = {\n",
    "            'train': train_dataset_gpu,\n",
    "            'eval': eval_dataset_gpu\n",
    "        }\n",
    "\n",
    "        data['train']['images'] = data['train']['images'].half().requires_grad_(False)\n",
    "        data['eval']['images']  = data['eval']['images'].half().requires_grad_(False)\n",
    "\n",
    "        data['train']['targets'] = F.one_hot(data['train']['targets']).half()\n",
    "        data['eval']['targets'] = F.one_hot(data['eval']['targets']).half()\n",
    "\n",
    "        torch.save(data, hyp['misc']['data_location'])\n",
    "\n",
    "else:\n",
    "    \n",
    "    data = torch.load(hyp['misc']['data_location'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExciteBlock(nn.Module):\n",
    "    def __init__(self, filters):\n",
    "        super(SqueezeExciteBlock, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.weight1 = nn.Parameter(torch.empty(self.filters, self.filters//32))\n",
    "        self.bias1 = nn.Parameter(torch.empty(1, self.filters//32))\n",
    "        self.weight2 = nn.Parameter(torch.empty(self.filters//32, self.filters))\n",
    "        self.bias2 = nn.Parameter(torch.empty(1, self.filters))\n",
    "\n",
    "        nn.init.xavier_uniform_(self.weight1)\n",
    "        nn.init.zeros_(self.bias1)\n",
    "        nn.init.xavier_uniform_(self.weight2)\n",
    "        nn.init.zeros_(self.bias2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        se = F.avg_pool2d(x, kernel_size=(x.shape[2], x.shape[3]))\n",
    "        se = se.reshape(shape=(-1, self.filters))\n",
    "        se = se * self.weight1 + self.bias1\n",
    "        se = F.relu(se)\n",
    "        se = se * self.weight2 + self.bias2\n",
    "        se = F.sigmoid(se).reshape(shape=(-1, self.filters, 1, 1))\n",
    "        se = x @ se\n",
    "        return se\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, h, w, x ,filters = 128, conv=3):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.h, self.w, self.x = h, w, x\n",
    "        self.cweights = nn.ParameterList([\n",
    "            nn.Parameter(torch.empty(filters, x if i == 0 else filters, conv, conv))\n",
    "            for i in range(3)\n",
    "        ])\n",
    "        self.cbiases = nn.ParameterList([\n",
    "            nn.Parameter(torch.empty(filters))\n",
    "            for i in range(3)\n",
    "        ])\n",
    "\n",
    "        for w in self.cweights:\n",
    "            nn.init.xavier_uniform_(w)\n",
    "        for b in self.cbiases:\n",
    "            nn.init.zeros_(b)\n",
    "\n",
    "        self._bn = nn.BatchNorm2d(128)\n",
    "        self._seb = SqueezeExciteBlock(filters)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.reshape(shape = (-1, self.x, self.w, self.h))\n",
    "        for cw, cb in zip(self.cweights, self.cbiases):\n",
    "            x = F.pad(x, (1,1,1,1))\n",
    "            x = F.conv2d(x, cw, bias=cb)\n",
    "            x = F.relu(x)\n",
    "        x = self._bn(x)\n",
    "        x = self._seb(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv = nn.ModuleList([ConvBlock(28,28,1), ConvBlock(28,28,128), ConvBlock(14,14,128)])\n",
    "        self.weight1 = nn.Parameter(torch.empty(128,10))\n",
    "        self.weight2 = nn.Parameter(torch.empty(128,10))\n",
    "\n",
    "        nn.init.xavier_uniform_(self.weight1)\n",
    "        nn.init.xavier_uniform_(self.weight2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv[0](x)\n",
    "        x = self.conv[1](x)\n",
    "        x = F.avg_pool2d(x ,kernel_size = (2,2)) \n",
    "        x = self.conv[2](x)\n",
    "        x1 = F.avg_pool2d(x,kernel_size = (14,14)).reshape(shape=(-1,128))\n",
    "        x2 = F.max_pool2d(x,kernel_size = (14,14)).reshape(shape=(-1,128))\n",
    "        xo = x1 * self.weight1 + x2 * self.weight2\n",
    "        return xo\n",
    "    \n",
    "    \n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lrs = [1e-4, 1e-5]\n",
    "    epochs = [2,1]\n",
    "    BS = 32\n",
    "\n",
    "    lmbd = 0.00025\n",
    "    \n",
    "    def lossfn(out, y):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        regularization_term = lmbd * (model.weight1.abs().sum() + model.weight2.abs().sum())\n",
    "        return criterion(out, y) + regularization_term\n",
    "    X_train, X_test, Y_train, Y_test = data['train']['images'], data['eval']['images'], data['train']['targets'], data['eval']['targets']\n",
    "    X_train = X_train.reshape(-1, 28, 28)\n",
    "    X_test = X_test.reshape(-1, 28, 28)\n",
    "    steps = len(X_train)//BS\n",
    "    np.random.seed(1337)\n",
    "    \n",
    "    model = ConvNet()\n",
    "\n",
    "    for lr,epoch in zip(lrs,epochs):\n",
    "        opt = nn.optim.Adam(model.parameters, lr = lrs[0])\n",
    "        for epch in range(1,epoch+1):\n",
    "            X_aug = X_train\n",
    "            \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'extra'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/jkr/ml_notebooks/mnistloader.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/mnistloader.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtinygrad\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m BatchNorm2d, optim\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/mnistloader.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtinygrad\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhelpers\u001b[39;00m \u001b[39mimport\u001b[39;00m getenv\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/mnistloader.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mextra\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m fetch_mnist\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'extra'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
