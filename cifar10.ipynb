{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [03:25<00:00, 828604.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cifar10/cifar-10-python.tar.gz to cifar10/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9f59e4e200>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jkr/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jkr/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jkr/ml_notebooks/cifar10.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m train_dataset_gpu \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m eval_dataset_gpu \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m train_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m], train_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [item\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mhyp[\u001b[39m'\u001b[39m\u001b[39mmisc\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m], non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_dataset_gpu_loader))]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m eval_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m],  eval_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m=\u001b[39m [item\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mhyp[\u001b[39m'\u001b[39m\u001b[39mmisc\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m], non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(eval_dataset_gpu_loader)) ]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m cifar10_std, cifar10_mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstd_mean(train_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m], dim\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)) \u001b[39m# dynamically calculate the std and mean from the data. this shortens the code and should help us adapt to new datasets!\u001b[39;00m\n",
      "\u001b[1;32m/home/jkr/ml_notebooks/cifar10.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m train_dataset_gpu \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m eval_dataset_gpu \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m train_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m], train_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [item\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mhyp[\u001b[39m'\u001b[39;49m\u001b[39mmisc\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mdevice\u001b[39;49m\u001b[39m'\u001b[39;49m], non_blocking\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_dataset_gpu_loader))]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m eval_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m],  eval_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m=\u001b[39m [item\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mhyp[\u001b[39m'\u001b[39m\u001b[39mmisc\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m], non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(eval_dataset_gpu_loader)) ]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jkr/ml_notebooks/cifar10.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m cifar10_std, cifar10_mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstd_mean(train_dataset_gpu[\u001b[39m'\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m'\u001b[39m], dim\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)) \u001b[39m# dynamically calculate the std and mean from the data. this shortens the code and should help us adapt to new datasets!\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    248\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "lt_conv_kwargs = {'kernel_size': 3, 'padding': 'same', 'bias': False}\n",
    "\n",
    "batchsize = 1024\n",
    "bias_scaler = 56\n",
    "\n",
    "hyp = {\n",
    "    'opt': {\n",
    "        'bias_lr':        1.64 * bias_scaler/512, # TODO: Is there maybe a better way to express the bias and batchnorm scaling? :'))))\n",
    "        'non_bias_lr':    1.64 / 512,\n",
    "        'bias_decay':     1.08 * 6.45e-4 * batchsize/bias_scaler,\n",
    "        'non_bias_decay': 1.08 * 6.45e-4 * batchsize,\n",
    "        'scaling_factor': 1./9,\n",
    "        'percent_start': .23,\n",
    "        'loss_scale_scaler': 1./128, # * Regularizer inside the loss summing (range: ~1/512 - 16+). FP8 should help with this somewhat too, whenever it comes out. :)\n",
    "    },\n",
    "    'net': {\n",
    "        'whitening': {\n",
    "            'kernel_size': 2,\n",
    "            'num_examples': 50000,\n",
    "        },\n",
    "        'batch_norm_momentum': .5, # * Don't forget momentum is 1 - momentum here (due to a quirk in the original paper... >:( )\n",
    "        'conv_norm_pow': 2.6,\n",
    "        'cutmix_size': 3,\n",
    "        'cutmix_epochs': 6,\n",
    "        'pad_amount': 2,\n",
    "        'base_depth': 64 ## This should be a factor of 8 in some way to stay tensor core friendly\n",
    "    },\n",
    "    'misc': {\n",
    "        'ema': {\n",
    "            'epochs': 10, # Slight bug in that this counts only full epochs and then additionally runs the EMA for any fractional epochs at the end too\n",
    "            'decay_base': .95,\n",
    "            'decay_pow': 3.,\n",
    "            'every_n_steps': 5,\n",
    "        },\n",
    "        'train_epochs': 12.1,\n",
    "        'device': 'cpu',\n",
    "        'data_location': 'data.pt',\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "if not os.path.exists(hyp['misc']['data_location']):\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "        cifar10      = torchvision.datasets.CIFAR10('cifar10/', download=True,  train=True,  transform=transform)\n",
    "        cifar10_eval = torchvision.datasets.CIFAR10('cifar10/', download=False, train=False, transform=transform)\n",
    "\n",
    "        # use the dataloader to get a single batch of all of the dataset items at once.\n",
    "        train_dataset_gpu_loader = torch.utils.data.DataLoader(cifar10, batch_size=len(cifar10), drop_last=True,\n",
    "                                                  shuffle=True, num_workers=2, persistent_workers=False)\n",
    "        eval_dataset_gpu_loader = torch.utils.data.DataLoader(cifar10_eval, batch_size=len(cifar10_eval), drop_last=True,\n",
    "                                                  shuffle=False, num_workers=1, persistent_workers=False)\n",
    "\n",
    "        train_dataset_gpu = {}\n",
    "        eval_dataset_gpu = {}\n",
    "\n",
    "        train_dataset_gpu['images'], train_dataset_gpu['targets'] = [item.to(device=hyp['misc']['device'], non_blocking=True) for item in next(iter(train_dataset_gpu_loader))]\n",
    "        eval_dataset_gpu['images'],  eval_dataset_gpu['targets']  = [item.to(device=hyp['misc']['device'], non_blocking=True) for item in next(iter(eval_dataset_gpu_loader)) ]\n",
    "\n",
    "        cifar10_std, cifar10_mean = torch.std_mean(train_dataset_gpu['images'], dim=(0, 2, 3)) # dynamically calculate the std and mean from the data. this shortens the code and should help us adapt to new datasets!\n",
    "\n",
    "        def batch_normalize_images(input_images, mean, std):\n",
    "            return (input_images - mean.view(1, -1, 1, 1)) / std.view(1, -1, 1, 1)\n",
    "\n",
    "        # preload with our mean and std\n",
    "        batch_normalize_images = partial(batch_normalize_images, mean=cifar10_mean, std=cifar10_std)\n",
    "\n",
    "        ## Batch normalize datasets, now. Wowie. We did it! We should take a break and make some tea now.\n",
    "        train_dataset_gpu['images'] = batch_normalize_images(train_dataset_gpu['images'])\n",
    "        eval_dataset_gpu['images']  = batch_normalize_images(eval_dataset_gpu['images'])\n",
    "\n",
    "        data = {\n",
    "            'train': train_dataset_gpu,\n",
    "            'eval': eval_dataset_gpu\n",
    "        }\n",
    "\n",
    "        ## Convert dataset to FP16 now for the rest of the process....\n",
    "        data['train']['images'] = data['train']['images'].half().requires_grad_(False)\n",
    "        data['eval']['images']  = data['eval']['images'].half().requires_grad_(False)\n",
    "\n",
    "        # Convert this to one-hot to support the usage of cutmix (or whatever strange label tricks/magic you desire!)\n",
    "        data['train']['targets'] = F.one_hot(data['train']['targets']).half()\n",
    "        data['eval']['targets'] = F.one_hot(data['eval']['targets']).half()\n",
    "\n",
    "        torch.save(data, hyp['misc']['data_location'])\n",
    "\n",
    "else:\n",
    "    ## This is effectively instantaneous, and takes us practically straight to where the dataloader-loaded dataset would be. :)\n",
    "    ## So as long as you run the above loading process once, and keep the file on the disc it's specified by default in the above\n",
    "    ## hyp dictionary, then we should be good. :)\n",
    "    data = torch.load(hyp['misc']['data_location'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
